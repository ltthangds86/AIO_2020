{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "ml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "name": "B4.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN565BbMxgRK"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEKx9XSexgRQ"
      },
      "source": [
        "iris = np.genfromtxt('iris_full.csv', dtype=None, delimiter=',', skip_header=1) \n",
        "X = iris[:, :4]\n",
        "y = iris[:, 4]\n",
        "y = y.astype('uint8')\n",
        "\n",
        "scaler = preprocessing.StandardScaler().fit(X)\n",
        "X = scaler.transform(X)\n",
        "\n",
        "intercept = np.ones((X.shape[0], 1))\n",
        "X = np.concatenate((intercept, X), axis=1)\n",
        "\n",
        "D = 4 # dimensionality\n",
        "K = 3 # number of classes\n",
        "\n",
        "# initialize parameters randomly\n",
        "theta = np.random.random((D+1, K))\n",
        "\n",
        "# gradient descent loop\n",
        "num_examples = X.shape[0]\n",
        "learning_rate = 0.01\n",
        "\n",
        "losses = []\n",
        "num_iter = 10000\n",
        "\n",
        "num_sample_stochastic = 10\n",
        "for epoch in tqdm(range(num_iter)):\n",
        "    for i in range(0, num_examples, num_sample_stochastic): \n",
        "        xi = X[i:i+num_sample_stochastic]\n",
        "        xi = xi.T\n",
        "        yi = y[i:i+num_sample_stochastic]\n",
        "\n",
        "        # evaluate class scores\n",
        "        scores = np.dot(theta.T, xi)\n",
        "        \n",
        "        #compute the class probabilities\n",
        "        exp_scores = np.exp(scores)\n",
        "        probs = exp_scores / np.sum(exp_scores, axis=0, keepdims=True)\n",
        "\n",
        "        # compute the loss\n",
        "        corect_logprobs = -np.log(probs[yi, range(num_sample_stochastic)])\n",
        "        loss = np.sum(corect_logprobs) / num_sample_stochastic\n",
        "        losses.append(loss)\n",
        "                \n",
        "        # compute the gradient on scores\n",
        "        dscores = probs\n",
        "        dscores[yi, range(num_sample_stochastic)] -= 1\n",
        "        \n",
        "        # backpropate the gradient to the parameters (W,b)\n",
        "        dtheta = np.dot(xi, dscores.T)\n",
        "\n",
        "        # perform a parameter update\n",
        "        theta += -learning_rate *dtheta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nRHkTsJxgRR"
      },
      "source": [
        "x_axis = range(len(losses))\n",
        "plt.plot(x_axis, losses, color=\"r\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOA5rYoAxgRS"
      },
      "source": [
        "# evaluate training set accuracy\n",
        "scores = np.dot(theta.T, X.T)\n",
        "predicted_class = np.argmax(scores, axis=0)\n",
        "print('Training accuracy: %.2f' % (np.mean(predicted_class == y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0HlQS9IxgRS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}